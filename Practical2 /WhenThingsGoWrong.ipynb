{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelAw432/DeepLearning/blob/main/Practical2%20/WhenThingsGoWrong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gREU7o3n-Z-3"
      },
      "source": [
        "# Deep Learning Practical 2 - Part 2 - When things go wrong!\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide you with an exercise in identifying issues when building and training a simple nerual network.\n",
        "\n",
        "Copyright (c) 2023 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caZAL4nPAV2H"
      },
      "source": [
        "We are going to have the entire setup and training loop in one cell here to make things a bit easier. We are going to be using the Ackbins dataset we saw during the lecture.\n",
        "\n",
        "There should be nothing new or surprising here but make sure you go through and understand every part of the code. Ask questions if there is something you don't understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_jLWMT5_f88"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from livelossplot import PlotLosses\n",
        "import os.path\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# get the dataset:\n",
        "if os.path.isdir('AckBinks'):\n",
        "    print (\"Dataset has already been downloaded...\")\n",
        "else:\n",
        "    !wget -q -O AckBinks.zip https://github.com/atapour/dl-pytorch/blob/main/2.Datasets/AckBinks/AckBinks.zip?raw=true\n",
        "    !unzip -q AckBinks.zip\n",
        "    !rm AckBinks.zip\n",
        "\n",
        "# transform images for training:\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(128),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print('created transforms for training set!')\n",
        "\n",
        "# create train dataset:\n",
        "train_dataset = torchvision.datasets.ImageFolder('AckBinks/train', train_transform)\n",
        "print(f\"There are {len(train_dataset)} images in the training set!\")\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print(*class_names, sep = \", \")\n",
        "\n",
        "# create dataloaders:\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "# we will use a ResNet model here - you will learn about these later\n",
        "# but you can see how easy CNNs are to use in PyTorch\n",
        "model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "num_infea = model.fc.in_features\n",
        "model.fc = nn.Linear(num_infea, 1)\n",
        "model = model.to(device)\n",
        "\n",
        "# create the optimiser:\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# since this is a binary problem, we will use binary cross entropy as the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# initialising epoch variable\n",
        "epoch = 0\n",
        "\n",
        "# to plot losses\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "# to keep the logs for loss plots\n",
        "logs = {}\n",
        "\n",
        "# main training loop:\n",
        "for epoch in range(5):\n",
        "\n",
        "    for j, batch in enumerate(train_loader):\n",
        "\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        y = y.reshape((y.shape[0], 1)).float()\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimiser.step()\n",
        "\n",
        "        # this is calculating the accuracy for the last batch\n",
        "        # accumulating values or a running mean would be better\n",
        "        y_prob = output > 0.5\n",
        "        accuracy = (y == y_prob).sum().item() / y.size(0)\n",
        "\n",
        "    print(epoch)\n",
        "    logs['Loss'] = loss.item()\n",
        "    logs['Accuracy'] = accuracy\n",
        "    liveloss.update(logs)\n",
        "    liveloss.send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQhMThKsRgA9"
      },
      "source": [
        "It should hopefully be clear to you that the model is not being trained well. The question is why!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5YIBjflXAcT"
      },
      "source": [
        "We know the model cannot be the problem as it is built into PyTorch - and off-the-shelf architectures in stable version of deep learning framework rarely go wrong.\n",
        "\n",
        "The dataset is fine, so there must be something wrong with our training process.\n",
        "\n",
        "The key thing for the model to train is calculating the gradients. So let's look at the gradients of one our layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86QW4pfNSS4d"
      },
      "outputs": [],
      "source": [
        "print(model.conv1.weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGXw0r-F6PQb"
      },
      "source": [
        "You should be getting a `None` value. Is that expected? Why is this happening? What could be the cause?\n",
        "\n",
        "It might help to understand how gradients are calculated in PyTorch. Have a look at this as it might shine some light on your issue:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n",
        "By this point, you should be familiar with the scientific method of debugging.\n",
        "\n",
        "And of course there are lots of resources (e.g. tutorials, documentation, discussion forums) to help you find issues. For instance, take a look at this, which is not exactly the issue we have, but should give you an idea as to what has happened:\n",
        "\n",
        "https://discuss.pytorch.org/t/how-to-print-the-computed-gradient-values-for-a-network/34179\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hvwczHnHDtQ"
      },
      "source": [
        "Hopefully, by this point, you will have resolved the issue and can now see gradients.\n",
        "\n",
        "Try to access the gradients of the parameters of our network and plot the histogram of the gradients to see how large or small they are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8uR01imHbOu"
      },
      "outputs": [],
      "source": [
        "# access gradient and try to plot histogram\n",
        "# ..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}