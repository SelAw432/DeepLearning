{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelAw432/DeepLearning/blob/main/BuildYourFirstNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Practical 2 - Building your first neural network\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide you with an excercise to practice building a simple nerual network.\n",
        "\n",
        "Copyright (c) 2022 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ],
      "metadata": {
        "id": "PpYxXHlx_XUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first excercise, we will be using SVHN dataset.\n",
        "\n",
        "As mentioned in [the dataset's website](http://ufldl.stanford.edu/housenumbers/), the Street View House Numbers (SVHN) Dataset can be seen as similar in flavour to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
        "\n",
        "In this practical, most elements of our code is missing. Your task is to complete the code.\n",
        "\n",
        "First, let's import what we need and set Torch to use the GPU:"
      ],
      "metadata": {
        "id": "iOFxUoiL_sUO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC2lNRDf-8xP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda')\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the data:"
      ],
      "metadata": {
        "id": "f_U68TsiC2Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.SVHN('data', split='train', download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "\n",
        "test_dataset = torchvision.datasets.SVHN('data', split='test', download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=256, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, drop_last=True)\n",
        "\n",
        "print(f\"There are {len(train_dataset)} images in the training set!\")\n",
        "print(f\"There are {len(test_dataset)} images in the test set!\")"
      ],
      "metadata": {
        "id": "Wys70EIgC17o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweak the parameters of the cell above (e.g. batch_size) as needed."
      ],
      "metadata": {
        "id": "FycIhaYHbr5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can already see that this dataset is much larger than MNIST and will be more challenging. Let's look at a few of our images:"
      ],
      "metadata": {
        "id": "Xli9aylwJlxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_loader.dataset[i][0].permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.xlabel(classes[train_loader.dataset[i][1]])"
      ],
      "metadata": {
        "id": "nsLzeXPDKD3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are getting to the good part. We want to build our neural network.\n",
        "\n",
        "Have a look at this tutorial, which should help you with how PyTorch supports building neural networks:\n",
        "\n",
        "[https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
        "\n",
        "Construct a neural network, using the which:\n",
        "- Has three Layers\n",
        "- Layer 1 is a Dense layer that recieves the input image flattened as a vector with a ReLU activation. Think about what the size of the input should be (i.e. how many neurons the network should have)\n",
        "- Layer 2 is a Dense layer with 512 neurons and ReLU activation\n",
        "- Layer 3 is a Dense layer that predicts what class the input belongs to"
      ],
      "metadata": {
        "id": "ucAI9ZULXzQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  # ....\n"
      ],
      "metadata": {
        "id": "18ikReBuXyZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create the model and the optimiser:"
      ],
      "metadata": {
        "id": "T5uCDUYUbF0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleMLP().to(device)\n",
        "\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(optimiser)"
      ],
      "metadata": {
        "id": "LsWWH24-bMoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need a loss function. Given that our problem is a classification one, which loss function do you think is most suitable?\n",
        "\n",
        "These haven't been covered in depth in the lectures, but take a look at these resources:\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "https://neptune.ai/blog/pytorch-loss-functions\n",
        "\n",
        "Complete the code below:"
      ],
      "metadata": {
        "id": "fSiKwuv9bdFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = ..."
      ],
      "metadata": {
        "id": "skcdcD0Och1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to start training. Some portion of the main loop has been completed for you but you will need to fill in the rest.\n",
        "\n",
        "You might find this tutorial useful:\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ],
      "metadata": {
        "id": "Vq4vFLT6cjxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0\n",
        "# training loop\n",
        "# train the model for 20 epochs:\n",
        "while (epoch < 20):\n",
        "\n",
        "    # iterate over the training dateset\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        # ....\n",
        "        # complete the training\n",
        "        # make sure you log and print the losses as well\n",
        "        # ....\n",
        "\n",
        "    epoch += 1"
      ],
      "metadata": {
        "id": "gFNWYIwbrQnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can take inspiration from the lecture material here:\n",
        "\n",
        "https://github.com/atapour/dl-pytorch/blob/main/4.Classifier/4_PyTorch_Programming_Classifier.ipynb\n",
        "\n",
        "and plot the loss curves live to see how the model is training. You can also draw the loss curves using [matplotlib](https://matplotlib.org/) or [Weights and Biases](https://wandb.ai), as we learned in the lecture today.\n",
        "\n",
        "What should the loss cureve look like? Does the loss curve you have plotted look as expected?"
      ],
      "metadata": {
        "id": "6IQc9TDTs4gN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the training is complete, it is time to test the model. Complete the main testing looop as well:"
      ],
      "metadata": {
        "id": "psI-_D67v522"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we are not training anything, we don't need gradients:\n",
        "with torch.no_grad():\n",
        "\n",
        "  # iterate over the testing dateset\n",
        "  for i, batch in enumerate(test_loader):\n",
        "\n",
        "    # sample x from the dataset\n",
        "    x, t = batch\n",
        "    x, t = x.to(device), t.to(device)\n",
        "\n",
        "    # ....\n",
        "    # complete the testing loop\n",
        "    # make sure you log and print the accuracy as well\n",
        "    # ....\n",
        "    # if you have are having trouble calculating and logging accuracy,\n",
        "    # you might want to take inspiration from the lecture material:\n",
        "    # https://github.com/atapour/dl-pytorch/blob/29652b1cf93222b50065be4498bd744dfae3fba3/4.Classifier/4_pytorch_programming_classifier.py\n",
        "    # the best way to learn code is to look at other code\n",
        "    # ...."
      ],
      "metadata": {
        "id": "GflyY8rLv5Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy level you are getting?"
      ],
      "metadata": {
        "id": "sIj6gdWExO-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have the time, go back to the cell where we created the model and change the architecture to see what difference it can make.\n",
        "\n",
        "You can start experimenting with Convolutional layers:\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
      ],
      "metadata": {
        "id": "Z6Th9hRUySzt"
      }
    }
  ]
}